{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 CTS GENERATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "u_train = pd.read_csv(os.path.join(\"data\", \"dataBenchmark.csv\"),header=0, thousands=',', decimal='.', na_values='NAN', usecols=['uEst']).to_numpy()\n",
    "u_test = pd.read_csv(os.path.join(\"data\", \"dataBenchmark.csv\"),header=0, thousands=',', decimal='.', na_values='NAN', usecols=['uVal']).to_numpy()\n",
    "y_train = pd.read_csv(os.path.join(\"data\", \"dataBenchmark.csv\"),header=0, thousands=',', decimal='.', na_values='NAN', usecols=['yEst']).to_numpy()\n",
    "y_test = pd.read_csv(os.path.join(\"data\", \"dataBenchmark.csv\"),header=0, thousands=',', decimal='.', na_values='NAN', usecols=['yVal']).to_numpy()\n",
    "\n",
    "print(u_train[0])\n",
    "# Compute rescaling factors using the training data\n",
    "u_mean = np.mean(u_train)\n",
    "u_std = np.std(u_train)\n",
    "y_mean = np.mean(y_train)\n",
    "y_std = np.std(y_train)\n",
    "\n",
    "# Rescale variables\n",
    "#u_train = (u_train - u_mean)/u_std\n",
    "#u_test = (u_test - u_mean) / u_std\n",
    "\n",
    "#y_train = (y_train - y_mean)/u_std\n",
    "#y_test = (y_test - y_mean) / u_std\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, sharex=True)\n",
    "ax[0].plot(u_train)  # u[V]\n",
    "ax[1].plot(y_train)  # h1 [m]\n",
    "\n",
    "if not os.path.exists(os.path.join(\"data\", \"CTS\")):\n",
    "    os.makedirs(os.path.join(\"data\", \"CTS\"))\n",
    "\n",
    "np.save(os.path.join(\"data\", \"CTS\", \"u_train.npy\"), u_train)\n",
    "np.save(os.path.join(\"data\", \"CTS\", \"u_test.npy\"), u_test)\n",
    "np.save(os.path.join(\"data\", \"CTS\", \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(\"data\", \"CTS\", \"y_test.npy\"), y_test)\n",
    "\n",
    "# Generate transfer and evaluation datasets\n",
    "\n",
    "\n",
    "# Rescale variables\n",
    "#u_transf = (u_transf - u_mean) / u_std\n",
    "#u_eval = (u_eval - u_mean) / u_std\n",
    "\n",
    "#y_transf = (y_transf - y_mean) / y_std\n",
    "#y_eval = (y_eval - y_mean) / y_std\n",
    "\n",
    "#fig, ax = plt.subplots(2, 1, sharex=True)\n",
    "#ax[0].plot(u_transf)  # u[V]\n",
    "#ax[1].plot(y_transf)  # h1 [m]\n",
    "\n",
    "#np.save(os.path.join(\"data\", \"CTS\", \"u_transf.npy\"), u_transf)\n",
    "#np.save(os.path.join(\"data\", \"CTS\", \"u_eval.npy\"), u_eval)\n",
    "#np.save(os.path.join(\"data\", \"CTS\", \"y_transf.npy\"),y_transf)\n",
    "#np.save(os.path.join(\"data\", \"CTS\", \"y_eval.npy\"), y_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 CTS TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from open_lstm import OpenLSTM\n",
    "from torchid import metrics\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seed for reproducibility\n",
    "n_context = 100  # Used to estimate the initial state in the RNN. State estimation is performed by opening the output prediction loop for the first n_context steps\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "num_iter = 10000  # gradient-based optimization steps\n",
    "#num_iter = 100  # gradient-based optimization steps\n",
    "lr = 1e-3  # learning rate\n",
    "test_freq = 10  # print a message every test_freq iterations\n",
    "\n",
    "# Load data (assuming data is two-dimensional)\n",
    "u_train = torch.tensor(np.load(os.path.join(\"data\", \"CTS\", \"u_train.npy\")).astype(np.float32))  # shape: [sequence_length, num_features]\n",
    "y_train = torch.tensor(np.load(os.path.join(\"data\", \"CTS\", \"y_train.npy\")).astype(np.float32))  # shape: [sequence_length, num_features]\n",
    "\n",
    "# Add batch dimension\n",
    "u_train = u_train.unsqueeze(0)  # Shape: [1, sequence_length, num_features]\n",
    "y_train = y_train.unsqueeze(0)  # Shape: [1, sequence_length, num_features]\n",
    "\n",
    "# Reshape into sequences of length = sequence_length\n",
    "sequence_length = 1024  # Adjust as needed\n",
    "num_features = u_train.shape[-1]  # Automatically determine number of features\n",
    "u_train = u_train.view(-1, sequence_length, num_features)  # Shape: [batch_size, sequence_length, num_features]\n",
    "y_train = y_train.view(-1, sequence_length, num_features)  # Shape: [batch_size, sequence_length, num_features]\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(u_train, y_train)\n",
    "\n",
    "# Create DataLoader with batch_size = 1024/sequence_length (1024 is the total size of the dataset)\n",
    "batch_size = round(1024/sequence_length)  # Adjust batch size if needed\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Iterate over batches\n",
    "for u_batch, y_batch in dataloader:\n",
    "    # Each batch will have shape [batch_size, sequence_length, num_features]\n",
    "    u_train = u_batch.view(-1, num_features)  # Flatten to [batch_size * sequence_length, num_features]\n",
    "    y_train = y_batch.view(-1, num_features)  # Flatten to [batch_size * sequence_length, num_features]\n",
    "    \n",
    "    print(u_train.shape)  # Expected: [batch_size * sequence_length, num_features]\n",
    "    print(y_train.shape)  # Expected: [batch_size * sequence_length, num_features]\n",
    "\n",
    "n_inputs = u_train.shape[-1]  # num_features\n",
    "\n",
    "# Concatenate the input and output for the model\n",
    "u_train = torch.cat((u_train[:, :], y_train[:, :]), -1)  # Concatenate along the feature dimension \n",
    "y_train = y_train[:, :]  # Adjust target by shifting \n",
    "\n",
    "#print(len(u_train.shape))\n",
    "# Initialize the model\n",
    "model = OpenLSTM(n_context, n_inputs,sequence_length)# \n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "LOSS = []\n",
    "y_sim = []\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop\n",
    "for itr in range(num_iter):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_sim = model(u_train)  # Model expects input of shape [batch_size * sequence_length, num_features]\n",
    "    loss = loss_fn(y_sim, y_train) #\n",
    "    loss.backward()\n",
    "\n",
    "    LOSS.append(loss.item())\n",
    "    if itr % test_freq == 0:\n",
    "        with torch.no_grad():\n",
    "            print(f'Iter {itr} | Train Loss {loss:.4f}')\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "print(f\"\\nTrain time: {train_time:.2f}\")\n",
    "\n",
    "# Save model\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")\n",
    "\n",
    "model_name = \"lstm-batched\"\n",
    "model_filename = f\"{model_name}.pt\"\n",
    "torch.save(model.state_dict(), os.path.join(\"models\", model_filename))\n",
    "\n",
    "R_sq_lin = metrics.r_squared(y_train[n_context:, :].detach().numpy(), y_sim[n_context:, :].detach().numpy()) #\n",
    "print(f\"R-squared Train model: {np.mean(R_sq_lin, axis=0)}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(2, 1, sharex=True)\n",
    "plt.suptitle(\"Train\")\n",
    "\n",
    "# Concatenate all sequences along the time axis\n",
    "y_train_np = y_train.detach().numpy()\n",
    "y_sim_np = y_sim.detach().numpy()\n",
    "u_train_np = u_train.detach().numpy()\n",
    "\n",
    "# Plot the concatenated sequences\n",
    "ax[0].plot(y_train_np[:, 0], label='Ground truth')\n",
    "ax[0].plot(y_sim_np[:, 0], label='Estimated fit')\n",
    "ax[0].axvline(n_context-1, color='k', linestyle='--', alpha=0.2)\n",
    "ax[0].set_ylabel('Y')\n",
    "ax[0].set_xlabel('X')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(u_train_np[:, 0], label=' u (Input Train)')\n",
    "ax[1].axvline(n_context-1, color='k', linestyle='--', alpha=0.2)\n",
    "ax[1].set_ylabel('Y')\n",
    "ax[1].set_xlabel('X')\n",
    "ax[1].legend()\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Test the model\n",
    "u_test = torch.tensor(np.load(os.path.join(\"data\", \"CTS\", \"u_test.npy\")).astype(np.float32))\n",
    "y_test = torch.tensor(np.load(os.path.join(\"data\", \"CTS\", \"y_test.npy\")).astype(np.float32))\n",
    "\n",
    "u_test = u_test.unsqueeze(0)  # Shape: [1, sequence_length, num_features]\n",
    "y_test = y_test.unsqueeze(0)  # Shape: [1, sequence_length, num_features]\n",
    "\n",
    "u_test = u_test.view(-1, sequence_length, num_features)  \n",
    "y_test = y_test.view(-1, sequence_length, num_features)  \n",
    "\n",
    "u_test = u_test.view(batch_size*sequence_length, -1)  # Flatten to [batch_size * sequence_length, num_features]\n",
    "y_test = y_test.view(batch_size*sequence_length, -1)  # Flatten to [batch_size * sequence_length, num_features]\n",
    "\n",
    "u_test = torch.cat((u_test[:, :], y_test[:, :]), -1)  # Concatenate along the feature dimension \n",
    "y_test = y_test[:, :] # \n",
    "\n",
    "with torch.no_grad():\n",
    "    y_sim = model(u_test)\n",
    "\n",
    "aux_batch_size_sequence_length = y_test.shape[0]\n",
    "R_sq_lin = metrics.r_squared(y_test[n_context:, :].detach().numpy(), y_sim[n_context:, :].detach().numpy()) #\n",
    "print(f\"R-squared Test model: {np.mean(R_sq_lin, axis=0)}\")\n",
    "\n",
    "# Plot test results\n",
    "fig, ax = plt.subplots(2, 1, sharex=True)\n",
    "plt.suptitle(\"Test\")\n",
    "\n",
    "# Concatenate all sequences along the time axis\n",
    "y_test_np = y_test.detach().numpy()\n",
    "y_sim_np = y_sim.detach().numpy()\n",
    "u_test_np = u_test.detach().numpy()\n",
    "\n",
    "# Plot the concatenated sequences\n",
    "ax[0].plot(y_test_np[:, 0], label='Ground truth')\n",
    "ax[0].plot(y_sim_np[:, 0], label='Estimated fit')\n",
    "ax[0].axvline(n_context - 1, color='k', linestyle='--', alpha=0.2)\n",
    "ax[0].set_ylabel('Y')\n",
    "ax[0].set_xlabel('X')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(u_test_np[:, 0], label='u (Input Test)')\n",
    "ax[1].axvline(n_context - 1, color='k', linestyle='--', alpha=0.2)\n",
    "ax[1].set_ylabel('Y')\n",
    "ax[1].set_xlabel('X')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct RealTime L4CasADi Model from PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1, 512] doesn't match the broadcast shape [1, 1, 512]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m f \u001b[38;5;241m=\u001b[39m cs\u001b[38;5;241m.\u001b[39mFunction(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf_approx\u001b[39m\u001b[38;5;124m'\u001b[39m, [u_sym, model_l4c\u001b[38;5;241m.\u001b[39mget_sym_params()], [y_sym])\u001b[38;5;66;03m#STOPPED HERE!!!\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#casadi_param = model_l4c.get_params(np.ones((n_inputs,batch_size*sequence_length)))\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m casadi_param \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_l4c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msequence_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(f)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Now, f can be used in optimization or simulations\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/l4casadi/realtime/realtime_l4casadi.py:75\u001b[0m, in \u001b[0;36mRealTimeL4CasADi.get_params\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_params\u001b[39m(\u001b[38;5;28mself\u001b[39m, a: Union[np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor]):\n\u001b[1;32m     74\u001b[0m     a_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(a)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 75\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(params) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/l4casadi/realtime/realtime_l4casadi.py:66\u001b[0m, in \u001b[0;36mRealTimeL4CasADi._get_params\u001b[0;34m(self, a_t)\u001b[0m\n\u001b[1;32m     64\u001b[0m     a_t \u001b[38;5;241m=\u001b[39m a_t\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_approximation_order \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m     df_a, f_a \u001b[38;5;241m=\u001b[39m \u001b[43mbatched_jacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_func_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [a_t\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), f_a\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), df_a\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()]\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_approximation_order \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/l4casadi/realtime/sensitivities.py:43\u001b[0m, in \u001b[0;36mbatched_jacobian\u001b[0;34m(func, inputs, create_graph, return_func_output)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_func_output:\n\u001b[1;32m     42\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m functorch\u001b[38;5;241m.\u001b[39mvmap(functorch\u001b[38;5;241m.\u001b[39mjacrev(func))(inputs)\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunctorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjacrev\u001b[49m\u001b[43m(\u001b[49m\u001b[43maux_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmap_randomness\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_func_output:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_functorch/vmap.py:434\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[1;32m    431\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_functorch/vmap.py:39\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_functorch/vmap.py:619\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 619\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:489\u001b[0m, in \u001b[0;36mjacrev.<locals>.wrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    488\u001b[0m     error_if_complex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacrev\u001b[39m\u001b[38;5;124m\"\u001b[39m, args, is_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 489\u001b[0m     vjp_out \u001b[38;5;241m=\u001b[39m \u001b[43m_vjp_with_argnums\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_aux\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m    491\u001b[0m         output, vjp_fn, aux \u001b[38;5;241m=\u001b[39m vjp_out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_functorch/vmap.py:39\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:291\u001b[0m, in \u001b[0;36m_vjp_with_argnums\u001b[0;34m(func, argnums, has_aux, *primals)\u001b[0m\n\u001b[1;32m    289\u001b[0m     diff_primals \u001b[38;5;241m=\u001b[39m _slice_argnums(primals, argnums, as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    290\u001b[0m     tree_map_(partial(_create_differentiable, level\u001b[38;5;241m=\u001b[39mlevel), diff_primals)\n\u001b[0;32m--> 291\u001b[0m primals_out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(primals_out, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(primals_out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/l4casadi/realtime/sensitivities.py:13\u001b[0m, in \u001b[0;36maux_function.<locals>.inner_aux\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner_aux\u001b[39m(inputs):\n\u001b[0;32m---> 13\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out, out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Paper_Reproduction/open_lstm_l4casadi.py:53\u001b[0m, in \u001b[0;36mOpenLSTML4casadi.forward\u001b[0;34m(self, u_train)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     state \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcn)\n\u001b[0;32m---> 53\u001b[0m     y_sim, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m#y_sim = y_sim.view(-1, self.n_inputs) # TO Flatten the output to [batch_size * sequence_length, num_features]\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_sim\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [1, 512] doesn't match the broadcast shape [1, 1, 512]"
     ]
    }
   ],
   "source": [
    "import l4casadi as l4c\n",
    "import os\n",
    "import casadi as cs\n",
    "import torch\n",
    "from open_lstm_l4casadi import OpenLSTML4casadi\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the model architecture as before\n",
    "n_context = 1  # Used for initial state estimation\n",
    "n_inputs = 1\n",
    "sequence_length = 1024  # Adjust as needed\n",
    "batch_size = 1\n",
    "# Initialize the model\n",
    "model = OpenLSTML4casadi(n_context, n_inputs, batch_size ,sequence_length, is_estimator=False)\n",
    "\n",
    "# Load the saved model weights\n",
    "model_name = \"lstm-batched\"\n",
    "model_filename = f\"{model_name}.pt\"\n",
    "\n",
    "assert os.path.exists(os.path.join(\"models\", model_filename)), \"Model file not found!\"\n",
    "model.load_state_dict(torch.load(os.path.join(\"models\", model_filename), map_location=\"cpu\"))\n",
    "\n",
    "model.estimate_state(torch.from_numpy(np.asarray(1.9914).reshape(1,1,1)).to(torch.float32),torch.from_numpy(np.asarray(5.122112274169922).reshape(1,1,1)).to(torch.float32),1)\n",
    "\n",
    "# Convert the PyTorch model to an L4CasADi model with batching\n",
    "model_l4c = l4c.realtime.RealTimeL4CasADi(model, device='cpu', approximation_order = 1, name=\"lstm_l4casadi_batched_realtime_rev1\")\n",
    "\n",
    "# Define the CasADi symbolic variable correctly\n",
    "# The shape should be [sequence_length, batch_size, n_inputs] for batched LSTM\n",
    "\n",
    "# Create a 2D symbolic matrix with the correct dimensions for LSTM input\n",
    "u_sym = cs.MX.sym('u', batch_size*sequence_length, n_inputs)\n",
    "print(u_sym.shape)\n",
    "y_sym = model_l4c(u_sym)\n",
    "f = cs.Function('f_approx', [u_sym, model_l4c.get_sym_params()], [y_sym])\n",
    "\n",
    "casadi_param = model_l4c.get_params(np.ones((n_inputs,batch_size*sequence_length)))\n",
    "print(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
